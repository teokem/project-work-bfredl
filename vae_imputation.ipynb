{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation of missing data using Variational Autoencoders\n",
    "==============\n",
    "\n",
    "By: BjÃ¶rn Linse, `bjorn.linse@thep.lu.se`\n",
    "\n",
    "Computational biology and Biological Physics, Dept. of Theoretical Physics.\n",
    "\n",
    "\n",
    "A common problem in statical analysis and machine learning with datasets is dealing with missing data. Typically this is done by separating the analysis in two steps: first we build an **imputation** model which seeks to fill in the missing values with predicted values. Then we can train the interesting target model (for instance regression and classification) on ostensibly complete data, which makes the formulation of the target model much simpler.\n",
    "\n",
    "Some simple practical imputation schemes are:\n",
    "\n",
    "- delete data rows with missing values\n",
    "- replace missing data values with the mean (or mode, median ...) value in the dataset\n",
    "- replace missing data value with randomly selected value from the same column\n",
    "\n",
    "These are simple schemes that do not use correlations among input columns. Another important distinction is between *single* imputation and *multiple* imputation. Single imputation just means filling in a single guess for each missing value. Multiple imputation instead means parameterizing a probability distribution over the missing values, from which then multiple values can be sampled. Some more advanced imputation techniques include\n",
    "\n",
    "* MICE (Multiple Imputation by Chained Equations)\n",
    "* $k$-NN ($k$ nearest neighbours)\n",
    "* PCA (principal component analysis)\n",
    "* autoencoding neural networks.\n",
    "\n",
    "If the target model can be described probabilistically, for instance a classifier can be formulates as outputting probabilities for different classes $y$, given complete data $x$, then, the sum rule of probability can be used to combine the models:\n",
    "\n",
    "$$ p(y|x^*) = \\int p(y|x)p(x|x^*) dx$$\n",
    "\n",
    "Where $p(x|x^*)$ are probabilities of complete data given a incomplete datapoint $x^*$\n",
    "\n",
    "Autoencoding neural networks have previously been used for single imputation. An autoencoder network aims to compress an input vector $x$ to a smaller representation vector $z$, from which an approxition of the full vector $x'$ can be restored.\n",
    "\n",
    "One of our ongoing research projects are trying to expand these methods to multiple imputation.\n",
    "For this we use variational autoencoders. They are **generative** models which describe a probability distribution over data points $p(x)$, from which can be sampled.\n",
    "\n",
    "![Variational Autoencoder](nb_graphics/vae.svg)\n",
    "\n",
    "Sampling is done in two steps. First $z$ is sampled from a (diagonal) unit normal distribution. Then a learnable function $g$, defined by a generator neural network, maps these to data vectors $x'=g(z;\\theta)$. Here $\\theta$ are the parameters of the neural network which completely determines the probability distribution.\n",
    "However, directly training this network from data (maximum likelihood) is not feasible, as we do not know what region in $z$-space that correspond to each data point.\n",
    "For this purpose a add second inference neural network $h(x,\\phi)$ is added. From an $x$ vector it should guess the conditional distribution $p(z|x)$, by outputting parameters to an approximating distribution $q(z|x)$.\n",
    "It can be shown that the true likelihood is bounded by the variational free energy (ELBO):\n",
    "$$ p(x) = \\int p(x|z)p(z) dz  > \\mathbb{E}_{q(z|x)}[p(x|z)] + D_{KL}( q(z|x) || p(z)) $$\n",
    "For a full derivation see the [original article](https://arxiv.org/abs/1312.6114).\n",
    "\n",
    "As the inference network doesn't just give a point estimate, but also approximates the distribution $p(z|y)$ variational autoencoder tries to represent the *uncertainty* of the representation. Our aim is to see if they can represent the uncertainty arising from missing values.\n",
    "\n",
    "Adapting the reconstruction loss function in the autoencoder is relatively straightforward: for each sample it should only sum the loss over the features are summed where the true value was known. An issue is however that the network requires complete input. We can bootstrap the process by some simple imputation scheme, like mean imputation. Then we can send the output of the network, mixed with the known values, back into the network. For a relatively simple problem like MNIST this process converges in a very few cycles, as we will see two cycles are often enough.\n",
    "\n",
    "![mixing values](nb_graphics/blanda.svg)\n",
    "\n",
    "## Implementation in keras\n",
    "\n",
    "We start with installing and importing necessary libraries.\n",
    "\n",
    "Unfortunately there has been some issues installing keras+tensorflow combination directly using anaconda/miniconda. In a conda-based envirionment, the recommended installation is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "conda install tensorflow\n",
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Layer, Input, Dense, Lambda\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, interact_manual\n",
    "from ipywidgets import IntSlider, SelectionSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use interactive widgets, you need to enable the notebook extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload this notebook if needed.\n",
    "\n",
    "As a simple example dataset, we use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) of hand written digits. To demonstrate imputation we will artificially remove various percentages of the dataset. In principle we could use a mask defined by independent binomial variables with the chosen $p$ visibility level. However images, especially simple mostly black and white drawings, have very high neighbour correlation so this would make reconstruction very easy. Instead I implemented a simple (Ising-model inspired) random process that removed pixels in a correlated fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_b,ytrain,ntrain,width,height = np.load(\"mnist_train.npy\")\n",
    "xvalid_b,yvalid,nvalid,width,height = np.load(\"mnist_valid.npy\")\n",
    "levels, masks_train, masks_valid = np.load(\"mnist_mask.npy\")\n",
    "xtrain = (xtrain_b/255.).astype(np.float32)\n",
    "xvalid = (xvalid_b/255.).astype(np.float32)\n",
    "\n",
    "xmean = np.mean(xtrain,axis=0)\n",
    "ni = width*height\n",
    "nh = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define reusable functions to show a grid of images. We show examples of the original MNIST training data, as well as masked data at various visibility levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showgrid(*cols, labels=None):\n",
    "    n = cols[0].shape[0]\n",
    "    cols = [c.reshape((n,height,width)) for c in cols]\n",
    "    gs = plt.GridSpec(n,len(cols),wspace=0.01)\n",
    "    for i,c in enumerate(cols):\n",
    "        for j in range(n):\n",
    "            ax = plt.subplot(gs[i+j*len(cols)])\n",
    "            ax.imshow(c[j], cmap='gray',extent=(0,c.shape[2],0,c.shape[1]))\n",
    "            if labels is not None and j == n-1:\n",
    "                ax.set_xlabel(labels[i])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_xticklabels([])\n",
    "\n",
    "# uglier but quicker: display an entire column at a time\n",
    "def showgrid2(*cols, labels=None):\n",
    "    n = cols[0].shape[0]\n",
    "    cols = [c.reshape((n*height,width)) for c in cols]\n",
    "    gs = plt.GridSpec(1,len(cols),wspace=0.01)\n",
    "    for i,c in enumerate(cols):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        ax.imshow(c, cmap='gray',extent=(0,c.shape[1],0,c.shape[0]))\n",
    "        for r in range(1,n):\n",
    "            plt.plot([0,width], [r*height, r*height], color='y', linestyle='-', linewidth=1)\n",
    "        ax.set_xlabel(labels[i])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "x,m = xtrain[:10], masks_train[:10]\n",
    "labels = [\"100 %\"] + [str(int(l*100))+\" %\" for l in levels[::-1]]\n",
    "plt.figure(1,figsize=(10,10))\n",
    "showgrid(x, *[x*(m <= i)+0.5*(m > i) for i in range(len(levels)-1,-1,-1)], labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class `MaskVAE` that implements a variational autoencoded with masked output. Most functionality we need already exists in keras, but we need to add the Gaussian activation in the $z$ layer as well as the VAE-specific loss function (with the mask modification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Lambda\n",
    "def gaussReparam(args):\n",
    "    mean, std = args\n",
    "    return mean +  std* K.random_normal(shape=K.shape(mean),\n",
    "                                        mean=0.0,\n",
    "                                        stddev=1.0)\n",
    "class MaskVAE:\n",
    "    def __init__(self,nh,nz):\n",
    "        reg_l2 = regularizers.l2(1e-4)\n",
    "        self.g_hlayer = Dense(nh, activation='relu', kernel_regularizer=reg_l2)\n",
    "        self.g_xlayer = Dense(ni, activation='sigmoid', kernel_regularizer=reg_l2)\n",
    "\n",
    "        self.i_hlayer = Dense(nh, activation='relu', kernel_regularizer=reg_l2)\n",
    "        self.i_mzlayer = Dense(nz, activation='linear', kernel_regularizer=reg_l2)\n",
    "        self.i_szlayer = Dense(nz, activation='softplus', kernel_regularizer=reg_l2, kernel_initializer='zeros')\n",
    "\n",
    "    def generator(self,z):\n",
    "        h = self.g_hlayer(z)\n",
    "        x = self.g_xlayer(h)\n",
    "        return x\n",
    "\n",
    "    def inference(self,xin,deterministic=False):\n",
    "        h = self.i_hlayer(xin)\n",
    "        mean_z = self.i_mzlayer(h)\n",
    "        std_z = self.i_szlayer(h)\n",
    "        z = gaussReparam([mean_z, std_z])\n",
    "        code_cost = -0.5*K.sum(1+2*K.log(std_z)-mean_z**2-std_z**2,axis=1)\n",
    "        return z, code_cost\n",
    "\n",
    "    def compile(self,optimizer='adam'):\n",
    "\n",
    "        xin = Input(shape=(ni,), name=\"x\")\n",
    "        xmask = Input(shape=(ni,), name=\"xmask\")\n",
    "\n",
    "        z, code_cost = self.inference(xin)\n",
    "        xrecon = self.generator(z)\n",
    "        self.model = Model([xin, xmask], xrecon)\n",
    "\n",
    "        def vae_loss(xtrue,xpred):\n",
    "            masked_loss = K.sum(K.binary_crossentropy(xtrue,xrecon)*xmask,axis=1)\n",
    "            return K.mean(code_cost+masked_loss)\n",
    "\n",
    "        def total_error(xtrue,xpred):\n",
    "            total_loss = K.sum(K.binary_crossentropy(xtrue,xrecon),axis=1)\n",
    "            return K.mean(total_loss)\n",
    "\n",
    "        def kl_code(*a):\n",
    "            return K.mean(code_cost)\n",
    "\n",
    "        self.model.compile(loss=vae_loss,optimizer=optimizer, metrics=[total_error, kl_code])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a helper function to display inputs and outputs of the network. For a sets of input, it will send in masked values, and sample 5 reconstructions. For each reconstruction we send the value through the network two times, and show the output after both the first and second iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showrecon(vae, xshow, mshow):\n",
    "    nsamp = 5\n",
    "    xmshow = xshow*mshow + 0.5*(1-mshow)\n",
    "    # As the autoencoder is indeterministic, repeat the process:\n",
    "    xin = xshow*mshow +xmean[None,:] *(1-mshow)\n",
    "    yshows = [vae.model.predict([xin,mshow]) for _ in range(nsamp)]\n",
    "    yshows2 = [vae.model.predict([xshow*mshow+ys*(1-mshow),mshow]) for ys in yshows]\n",
    "\n",
    "    ymix = list(chain(*zip(yshows,yshows2)))\n",
    "    labels = [\"original\", \"masked\"] + nsamp * [\"1 iter\", \"2 iters\"]\n",
    "    showgrid2(xshow,xmshow,*ymix,labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating a VAE model\n",
    "\n",
    "We can now train an example model, the following uses 50% visible data, and 20 $z$ feature dimensions.\n",
    "With GPU acceleration this should take a minute or two. Without GPU, if this takes to long time, feel free to skip this cell (pre-trained models will be loaded below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "print(\"visibility level:\", levels[j])\n",
    "mtrain = 1*(masks_train <= j)\n",
    "mvalid = 1*(masks_valid <= j)\n",
    "\n",
    "vae = MaskVAE(ni,20)\n",
    "adam = Adam(lr=0.002)\n",
    "vae.compile(adam)\n",
    "xmasked = xtrain*mtrain+ xmean[None,:]*(1-mtrain)\n",
    "vae.model.fit([xmasked,mtrain],xtrain,epochs=40,batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check how well the model works on the valitation set. If interactive widgets are activated, it is possible to explore the first 400 examples in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theplot(index):\n",
    "    xshow = xvalid[index*10:(index+1)*10]\n",
    "    mshow = mvalid[index*10:(index+1)*10]\n",
    "    plt.figure(1,figsize=(20,20))\n",
    "    showrecon(vae,xshow,mshow)\n",
    "    plt.show()\n",
    "\n",
    "index = IntSlider(min=0,max=40-1,step=1,value=0, continous_update=False)\n",
    "interact(theplot, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train multiple models, on different visibility levels as well as with different network parameters. Due to timing constraints, only one parameter is varied, the feature vector size. In production use more parameters would need to be varied, such as hidden layer size (here fixed to input size), number of hidden layers as well as regularization.\n",
    "\n",
    "Training all the parameters would take quite a bit of time, especially without GPU acceleration. Therefore with this notebook, a set of pre-trained models are included and loaded by default. By setting `dotrain` to true, these can be reproduced (this takes roughly half an hour with GPU, probably several hours without GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotrain = False\n",
    "\n",
    "nz_s = [2,3,5,10,20,50]\n",
    "#nz_s = [2,5,20,50]\n",
    "lvls = list(enumerate(levels))\n",
    "models = {}\n",
    "for nz in nz_s:\n",
    "    for j,lvl in lvls:\n",
    "        fn = \"vae_models/vae_{}_{}.npy\".format(nz,j)\n",
    "        mtrain = 1*(masks_train <= j)\n",
    "\n",
    "        vae = MaskVAE(ni,nz)\n",
    "        adam = Adam(lr=0.002,decay=0.001)\n",
    "        vae.compile(adam)\n",
    "        if dotrain:\n",
    "            vae.model.fit([xmasked,mtrain],xtrain,epochs=20,batch_size=200)\n",
    "            vae.model.save_weights(fn)\n",
    "        else:\n",
    "            vae.model.load_weights(fn)\n",
    "        models[nz,j] = vae\n",
    "\n",
    "        xmasked = xtrain*mtrain+ xmean[None,:]*(1-mtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use interactive widgets to explore the dataset as well as parameter variation. Note we can vary the visibility level of the validation set (`valid_level`) independently of the training set used to train the model (`train_level`). For instance this can be used to check the robustness of the model, if the model can handle inputs with different visibility than it was trained on. Not that the reconstructed images come in pairs: after one and two iterations trough the autoencoder, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theplot(index,nz,train_level,valid_level):\n",
    "    tj = levels.index(train_level)\n",
    "    vj = levels.index(valid_level)\n",
    "    xshow = xvalid[index*10:(index+1)*10]\n",
    "    mshow = 1*(masks_valid[index*10:(index+1)*10] <= vj)\n",
    "    vae = models[nz,tj]\n",
    "    plt.figure(1,figsize=(10,10))\n",
    "    showrecon(vae,xshow,mshow)\n",
    "    plt.show()\n",
    "\n",
    "index = IntSlider(min=0,max=40-1,step=1,value=0, continous_update=False)\n",
    "nzi = SelectionSlider(options=nz_s,value=20)\n",
    "level = SelectionSlider(options=levels, value=0.6)\n",
    "level2 = SelectionSlider(options=levels, value=0.6)\n",
    "index = IntSlider(min=0,max=40-1,step=1,value=0, continous_update=False)\n",
    "interact(theplot, nz=nzi, train_level=level, valid_level=level2, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation\n",
    "\n",
    "As a direct performance measure we can use the MSE (mean square error) of the validation set under the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mean_exp(logl, axis=-1):\n",
    "    maxv = logl.max(axis=axis,keepdims=True)\n",
    "    ivals = np.log(np.mean(np.exp(logl-maxv), axis=axis))\n",
    "    vals=ivals+np.squeeze(maxv,axis=axis)\n",
    "    return vals\n",
    "\n",
    "nz_test = [2,3,5,10,20,50]\n",
    "ntries = 5\n",
    "j,lvl = lvls[1]\n",
    "scores = np.zeros((len(nz_s), len(lvls), 2))\n",
    "scores.shape\n",
    "for i,nz in enumerate(nz_s):\n",
    "    for j,lvl in lvls:\n",
    "        vae = models[nz,j]\n",
    "        mask = 1*(masks_valid <= j)\n",
    "        logls = np.zeros((2,nvalid,ntries))\n",
    "        xin = xvalid*mask+xmean[None,:]*(1-mask)\n",
    "        for k in range(ntries):\n",
    "            y = vae.model.predict([xin,mask], batch_size=512)\n",
    "            xin = xvalid*mask+y*(1-mask)\n",
    "            y2 = vae.model.predict([xvalid,mask], batch_size=512)\n",
    "            logls[:,:,k] = [-((yi-xvalid)**2*(1-mask)).sum(axis=1)/2 for yi in [y,y2]]\n",
    "        # MSE is a (negative) log-likelihood measure, average it as such\n",
    "        logls = log_mean_exp(logls,axis=2)\n",
    "        scores[i,j,:] = logls.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the error as function of visibility level and feature layer size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for nit in range(2):\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    for i,nz in enumerate(nz_s):\n",
    "        plt.plot(levels,-scores[i,:,nit].T,'o-'+nit*'.',label='nz={} niter={}'.format(nz,nit+1))\n",
    "plt.xlabel(\"visibility level\")\n",
    "plt.ylabel(\"Error (MSE)\")\n",
    "plt.grid()\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said initially, we are often not interested in the performance of the imputation model _per se_, rather it is a pre-processing step for an interesting target model. For MNIST, we can demonstrate this by training a classifier of the different digits, that uses the imputed values instead of the true values (which in a realistic application of course is not known!) \n",
    "We use multiple imputation in both training and evaluation. In training we sample new imputed values for each epoch, and in evaluation we average class probabilities over multiple imputations. As a score function we use the number of correctly classified examples, as determined by the averaged probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(vae,j,niter=2):\n",
    "    ntries = 5\n",
    "    mtrain = 1*(masks_train <= j)\n",
    "    mvalid = 1*(masks_valid <= j)\n",
    "    mlp = Sequential([\n",
    "        Dense(500,activation='relu',input_shape=(ni,)),\n",
    "        Dense(10,activation='softmax'),\n",
    "        ])\n",
    "    adam = Adam(lr=0.005)\n",
    "    mlp.compile(loss='sparse_categorical_crossentropy', optimizer=adam)\n",
    "    for i in range(2):\n",
    "        xin = xtrain*mtrain+xmean[None,:]*(1-mtrain)\n",
    "        for _ in range(niter):\n",
    "            ximp = vae.model.predict([xin,mtrain], batch_size=512)\n",
    "            xin = xtrain*mtrain+ximp*(1-mtrain)\n",
    "        mlp.fit(xin,ytrain,epochs=1, batch_size=512)\n",
    "\n",
    "    outputs = []\n",
    "    for i in range(ntries):\n",
    "        xin = xvalid*mvalid+xmean[None,:]*(1-mvalid)\n",
    "        for _ in range(niter):\n",
    "            ximp = vae.model.predict([xin,mvalid], batch_size=512)\n",
    "            xin = xvalid*mvalid+ximp*(1-mvalid)\n",
    "        out = mlp.predict(xin)\n",
    "        outputs.append(out)\n",
    "    pred = np.mean(outputs,axis=0)\n",
    "    best = pred.argmax(axis=1)\n",
    "    score = (best == yvalid).mean()\n",
    "    return score\n",
    "\n",
    "#nz_c = [2,3,5,10,20,50]\n",
    "nz_c= [5,10,50]\n",
    "cscores = np.zeros((len(nz_c), len(lvls), 2))\n",
    "for i,nz in enumerate(nz_c):\n",
    "    for j,lvl in lvls:\n",
    "        vae = models[nz,j]\n",
    "        for k in range(2):\n",
    "            cscores[i,j,k] = evaluate(vae,j,niter=k+1)\n",
    "baseline = np.zeros(len(lvls))\n",
    "for j,lvl in lvls:\n",
    "    baseline[j] = evaluate(None,j,niter=0)\n",
    "goldstandard = evaluate(None,len(levels),niter=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the classification performance depending on the visibility level. As baseline we use mean imputation only. As a relative \"gold standard\" we train the same classification model with the complete dataset. (Of course, the true gold standard for MNIST is a lot better, but this is for the demonstration of the effect of missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for nit in range(2):\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    for i,nz in enumerate(nz_c):\n",
    "        plt.plot(levels,cscores[i,:,nit].T,*(nit*['-.']),label='nz={} niter={}'.format(nz,nit+1))\n",
    "plt.plot(levels,baseline,'k',label='baseline')\n",
    "plt.plot([levels[0], levels[-1]],[goldstandard,goldstandard],'k-.', label='gold standard')\n",
    "plt.xlabel(\"visibility level\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a clear improvement over baseline, but there is much room for improvement (by more complex network architectures, better training techniques). Of course, comparison to state-of-art imputation methods like $k$-nearest neighbours, deterministic autoencoders and MICE should also be done, but I didn't have the time to do this in scope of this notebook project."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
